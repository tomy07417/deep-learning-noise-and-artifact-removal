{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4e03fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "DIR_VIDEO_EJEMPLO = './mmnist-medium/batch_0_video_0.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f442f1a",
   "metadata": {},
   "source": [
    "# Páginas y papers utilizados\n",
    "\n",
    "### Dataset\n",
    "* Dataset a utilizar: https://www.kaggle.com/datasets/yichengs/captioned-moving-mnist-dataset-medium-version\n",
    "\n",
    "### Arquitectura\n",
    "* Unet 2D: https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/\n",
    "* Video explicativo: https://www.youtube.com/watch?v=waIPUsecaaQ\n",
    "\n",
    "* Temporal smoothing\n",
    "\n",
    "Cuando tu UNet procesa cada frame por separado, pasa lo siguiente:\n",
    "El frame 0 → la red lo corrige de UNA forma\n",
    "El frame 1 → lo corrige levemente distinto\n",
    "El frame 2 → también distinto\n",
    "\n",
    "Aunque todos los frames sean parecidos, la red nunca da EXACTAMENTE la misma salida.\n",
    "Eso genera un efecto feo en video llamado Flickering (parpadeo visual)\n",
    "El video reconstruido “tiembla”, los colores cambian un poco, las texturas vibran frame a frame.\n",
    "No es un error del modelo, es una consecuencia de que no ve el tiempo.\n",
    "El temporal smoothing es una técnica muy simple que suaviza la transición entre frames reconstruidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2333349",
   "metadata": {},
   "source": [
    "# Visualización del video (sin mancha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d3239f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(DIR_VIDEO_EJEMPLO)\n",
    "\n",
    "if not video.isOpened():\n",
    "    print(\"No se pudo abrir el video\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Opcional: ventana completa\n",
    "    cv2.namedWindow(\"Video\", cv2.WINDOW_NORMAL)\n",
    "    cv2.setWindowProperty(\"Video\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fb8c63",
   "metadata": {},
   "source": [
    "# Generación de mancha en el vídeo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9dc9a4",
   "metadata": {},
   "source": [
    "## Obtener los frames del vídeo\n",
    "* T → Tiempo (cantidad de frames)\n",
    "* H → Alto del frame (Height)\n",
    "* W → Ancho del frame (Width)\n",
    "* C → Canales de color (Channels)\n",
    "    * 0 → Red\n",
    "    * 1 → Green\n",
    "    * 2 → Blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e65acf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 72, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(DIR_VIDEO_EJEMPLO)\n",
    "\n",
    "frames = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frames.append(frame)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "frames = np.array(frames)  # shape: (T, H, W, 3)\n",
    "print(frames.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f6a89e",
   "metadata": {},
   "source": [
    "## Generación de la mancha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54a99010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_circular_stain(h, w, radius=25, opacity=1, hardness=0.8):\n",
    "    # Centro aleatorio\n",
    "    cx = np.random.randint(radius, w - radius)\n",
    "    cy = np.random.randint(radius, h - radius)\n",
    "\n",
    "    y, x = np.ogrid[:h, :w]\n",
    "    dist = np.sqrt((x - cx)**2 + (y - cy)**2)\n",
    "\n",
    "    # Distancia normalizada 0..1\n",
    "    norm = dist / radius\n",
    "\n",
    "    # \"hardness\" controla qué tan abrupto es el borde\n",
    "    mask = np.clip(1 - norm, 0, 1)**hardness\n",
    "\n",
    "    # opacidad de la mancha\n",
    "    mask = mask * opacity\n",
    "\n",
    "    return mask[..., None]\n",
    "\n",
    "def apply_stain_to_video(frames, stain_mask):\n",
    "    stained = []\n",
    "    for frame in frames:\n",
    "        frame_f = frame / 255.0\n",
    "        stain = np.ones_like(frame_f) * stain_mask\n",
    "\n",
    "        # Combinar (mancha oscurece + teñido)\n",
    "        corrupted = frame_f * (1 - stain_mask) + (0.3 * stain)\n",
    "        corrupted = np.clip(corrupted, 0, 1)\n",
    "        \n",
    "        stained.append((corrupted * 255).astype(np.uint8))\n",
    "\n",
    "    return np.array(stained)\n",
    "\n",
    "\n",
    "def save_video(frames, filename=\"video_con_manchas.mp4\", fps=24):\n",
    "    h, w = frames[0].shape[:2]\n",
    "    writer = cv2.VideoWriter(\n",
    "        filename,\n",
    "        cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "        fps,\n",
    "        (w, h)\n",
    "    )\n",
    "    for f in frames:\n",
    "        writer.write(cv2.cvtColor(f, cv2.COLOR_RGB2BGR))\n",
    "    writer.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2622d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames\n",
    "\n",
    "# Genero una mancha circular\n",
    "mask = generate_circular_stain(frames.shape[1], frames.shape[2])\n",
    "\n",
    "# Aplico la mancha al video\n",
    "frames_con_manchas = apply_stain_to_video(frames, mask)\n",
    "\n",
    "# Guardo el video con manchas\n",
    "save_video(frames_con_manchas, filename=\"video_con_manchas_circulares_ejemplo.mp4\", fps=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e845f4a9",
   "metadata": {},
   "source": [
    "# Visualización del video con la mancha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ace583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_mancha_circular = cv2.VideoCapture(\"./video_con_manchas_circulares_ejemplo.mp4\")\n",
    "\n",
    "if not video_mancha_circular.isOpened():\n",
    "    print(\"No se pudo abrir el video\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_mancha_circular.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Opcional: ventana completa\n",
    "    cv2.namedWindow(\"Video\", cv2.WINDOW_NORMAL)\n",
    "    cv2.setWindowProperty(\"Video\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_mancha_circular.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17f11cf",
   "metadata": {},
   "source": [
    "# Conclusión\n",
    "Se le generó al video original una mancha y por el alcance de este proyecto y el tipo de video que queremos procesar conviene acortar el video a un clip que sea de entre 5 y 10 segundos ya que la mancha no se va a mover. Esto evitaria ocupar menos espacio para el almacenamiento del dataset y también la velocidad de entrenamiento del modelo, ya que cada video tendría menos frames para analizar que los originales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
